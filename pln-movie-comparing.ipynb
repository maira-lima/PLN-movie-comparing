{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de Filmes pelas Reviews no IMDB\n",
    "\n",
    "## Processamento de Linguagem Natural\n",
    "\n",
    "Maira Zabuscha de Lima\n",
    "\n",
    "21008214\n",
    "\n",
    "Professor Jesús P. Mena-Chalco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import requests\n",
    "import numpy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada de usuário\n",
    "\n",
    "Preencha o código e nome do filme a ser comparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = 'tt4786282'\n",
    "name = 'Lights Out'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exprexssões Regulares\n",
    "\n",
    "Aqui são definidas duas expressões regulares:\n",
    "* tag - Localiza o texto das reviews dentro de sua tag HTML.\n",
    "* regex - Localiza todas as palavras dentro de cada review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = re.compile(r'<div class=\"text show-more__control\">(.+?)</div>', re.DOTALL)\n",
    "\n",
    "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "O arquivo stopwords.txt contém uma lista de palavras em inglês para serem ignoradas na leitura das reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 stopwords\n"
     ]
    }
   ],
   "source": [
    "Stopwords = set([]) \n",
    "sw = open(\"stopwords.txt\",'r')\n",
    "for s in sw.readlines():\n",
    "    Stopwords.add(s.strip().lower())\n",
    "sw.close()\n",
    "print(\"{0} stopwords\".format(len(Stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filmes classificados\n",
    "\n",
    "O arquivo ratings.csv pode ser obtido em sua página de usuário do IMDB em uma url do tipo:\n",
    "\n",
    "https://www.imdb.com/user/ur24136776/ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 filmes\n"
     ]
    }
   ],
   "source": [
    "f = open('ratings-short.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "lines = list(reader)\n",
    "f.close()\n",
    "lines = lines[1:]\n",
    "print(\"{0} filmes\".format(len(lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis\n",
    "\n",
    "As seguintes variáveis vão guardar as informações que o algoritmo utilizará:\n",
    "* Document - dicionário com elementos do tipo ('código do filme', list()) onde a lista contém as palavras retiradas das reviews exceto as stopwords.\n",
    "* Title - dicionário com elementos do tipo ('código do filme', 'título do filme').\n",
    "* Rating - dicionário com elementos do tipo ('código do filme', 'rating do filme').\n",
    "* Vocabulary - conjunto com todas as palavras do vocabulário de todos os filmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document = dict([])\n",
    "Title = dict([])\n",
    "Rating = dict([])\n",
    "Vocabulary = set([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função leFilme\n",
    "\n",
    "Essa função acessa o site imdb.com e retira as reviews de todos os filmes listados em ratings.csv, preenchendo as variáveis acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leFilme(movieCode, movieTitle, movieRating):\n",
    "    url = 'https://www.imdb.com/title/' + movieCode + '/reviews'\n",
    "    #print(url)\n",
    "    res = requests.get(url)\n",
    "    words = list()\n",
    "    if res.status_code == requests.codes.ok:\n",
    "        conteudo = res.text\n",
    "        reviews = tag.findall(conteudo)\n",
    "        if len(reviews) > 0:\n",
    "            txt = '\\n'.join(reviews).replace('&#39;', '\\'').replace('<br/>', ' ').replace('&quot;', '\\\"').replace('&amp;', '&')\n",
    "            txt = re.sub(r'[^\\x00-\\x7f]',r'', txt)\n",
    "            words = re.findall(regex, txt)\n",
    "    if len(words) > 0:\n",
    "        Document[movieCode] = list()\n",
    "        for w in words:\n",
    "            if w not in Stopwords and len(w)>=3:\n",
    "                Document[movieCode].append(w.lower())\n",
    "        if len(Document[movieCode]) > 0:\n",
    "            Vocabulary.update(Document[movieCode])\n",
    "            Title[movieCode] = movieTitle\n",
    "            Rating[movieCode] = movieRating\n",
    "        else:\n",
    "            del Document[movieCode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das reviews\n",
    "\n",
    "Aqui a função acima é chamada para cada filme, inclusive o filme provido pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 documentos\n",
      "20200 palavras\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    leFilme(line[0], line[3], line[1])\n",
    "leFilme(movie, name, '0')\n",
    "\n",
    "D = len(Document)\n",
    "V = len(Vocabulary)\n",
    "print(\"{} documentos\".format(D))\n",
    "print(\"{} palavras\".format(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de freqüências\n",
    "\n",
    "A matriz de freqüências M é uma matriz com V linhas, para cada palavra, e D colunas, para cada filme. Cada coluna é o vetor de um filme, com cada elemento do vetor sendo a freqüência de uma palavra do vocabulário nesse filme.\n",
    "\n",
    "Essa etapa pode ser bem demorada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = numpy.zeros((V, D))\n",
    "documents  = list(Document.keys())\n",
    "vocabulary = list(Vocabulary)\n",
    "for j in range(0, D):\n",
    "    d = documents[j]       \n",
    "    #print(\"{0:.0f}%\".format(((j/D)*100)), end=' ')\n",
    "    for i in range(0, V):\n",
    "        w = vocabulary[i]       \n",
    "        M[i,j] = float(Document[d].count(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz TF-IDF\n",
    "\n",
    "TF (Term-Frequency) é o vetor do documento normalizado pelo seu tamanho.\n",
    "\n",
    "IDF (Inverse Document Frequency) é um vetor cujo tamanho é o tamanho do vocabulário e pra cada palavra do vocabulário calcula:\n",
    "\n",
    "idf(w) = log(D / D(w)), onde D(w) é a quantidade de documentos que contém w.\n",
    "\n",
    "Quanto mais comum for a palavra, mais seu valor de IDF tenderá a zero.\n",
    "\n",
    "A matriz TF-IDF é obtida, então, multiplicando-se cada vetor TF pelo vetor IDF e concatenado-os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = numpy.count_nonzero(M, axis=1)\n",
    "idf = [D / x for x in idf]\n",
    "idf = numpy.log(idf)\n",
    "Sd = numpy.sum(M, axis=0)\n",
    "TFIDF = numpy.copy(M)\n",
    "for j in range(0, D): \n",
    "    TFIDF[:,j] = [x / Sd[j] for x in TFIDF[:,j]]\n",
    "    TFIDF[:,j] = numpy.multiply(TFIDF[:,j], idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de distância\n",
    "\n",
    "Aqui definimos dois dicionários para administrar todas as medidas de distância disponíveis para, então, avaliarmos a diferença que a escolha da medida causa no resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_f = {'euclidean': distance.euclidean, \n",
    "          'chebyshev': distance.chebyshev, \n",
    "          'cosine': distance.cosine}\n",
    "dist = {'euclidean': numpy.ones(D-1) * numpy.nan, \n",
    "          'chebyshev': numpy.ones(D-1) * numpy.nan, \n",
    "          'cosine': numpy.ones(D-1) * numpy.nan,\n",
    "          'tf-idf': numpy.ones(D-1) * numpy.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da distância\n",
    "\n",
    "O cálculo da distância é repetido para todas as medidas acima na matriz M e também para a distância cosseno na matriz TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, D-1): \n",
    "    for df in dist_f.keys():\n",
    "        dist[df][i] = dist_f[df](M[:,i], M[:,-1])\n",
    "    \n",
    "    dist['tf-idf'][i] = distance.cosine(TFIDF[:,i], TFIDF[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da similaridade\n",
    "\n",
    "A similaridade é calculada como (1 - distancia normalizada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = dict()\n",
    "for df in dist.keys():\n",
    "    similarity[df] = 1 - (dist[df] - numpy.nanmin(dist[df])) / (numpy.nanmax(dist[df]) - numpy.nanmin(dist[df]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Os 5 filmes mais similares por cada uma das medidas é exbido, além de sua nota extraída de ratings.csv. Em parênteses o valor da similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Titulos mais similares a Lights Out por distancia euclidean e suas notas:\n",
      " 6 - The Ritual (1.00)\n",
      " 8 - The Void (0.91)\n",
      " 7 - Get Out (0.91)\n",
      "10 - Grave Encounters (0.88)\n",
      " 5 - As Above, So Below (0.87)\n",
      "\n",
      "Titulos mais similares a Lights Out por distancia chebyshev e suas notas:\n",
      " 6 - The Tunnel (1.00)\n",
      " 8 - The Void (0.99)\n",
      " 5 - As Above, So Below (0.99)\n",
      "10 - The Skeleton Key (0.97)\n",
      " 5 - Gok-seong (0.97)\n",
      "\n",
      "Titulos mais similares a Lights Out por distancia cosine e suas notas:\n",
      " 6 - The Ritual (1.00)\n",
      " 8 - The Cabin in the Woods (0.91)\n",
      " 6 - It Follows (0.90)\n",
      " 5 - Chernobyl Diaries (0.89)\n",
      " 5 - Gok-seong (0.89)\n",
      "\n",
      "Titulos mais similares a Lights Out por distancia tf-idf e suas notas:\n",
      "10 - Grave Encounters (1.00)\n",
      " 6 - It Follows (0.92)\n",
      " 7 - Get Out (0.80)\n",
      " 5 - Paranormal Activity 3 (0.76)\n",
      " 6 - The Ritual (0.53)\n"
     ]
    }
   ],
   "source": [
    "for df in dist.keys():\n",
    "    idx = numpy.argsort(similarity[df])\n",
    "    txt = '\\nTitulos mais similares a ' + name + ' por distancia ' + df + ' e suas notas:'\n",
    "    for i in range(-1, -6, -1):\n",
    "        txt += '\\n{1} - {0} ({2:.2f})'.format(Title[documents[idx[i]]], Rating[documents[idx[i]]].rjust(2), similarity[df][idx[i]])\n",
    "    \n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
